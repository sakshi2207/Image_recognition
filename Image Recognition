from mnist_loader import load_data_wrapper
import numpy as np
import matplotlib.pyplot as plt

B1=np.random.randn(30,1)
B2=np.random.randn(10,1)
 for j in range (epochs):
  random.shuffle(Training_data)
   for k in range(0,n,mini_batch_size):
    mini_batch=training_data[k:k+mini_batch_size]
    X,Y=vectorize_mini_batch(mini_batch)

#Feed Forword
Z1=np.dot(W1,x)+B1
A1=Sigmoid(Z1)
Z2=np.dot(W2,x)+B2
A2=Sigmoid(Z2)

#Backpropogate
dZ2=1/mini_batch_size*(A2-Y)*sigmoid_prime(Z2)
dW2=np.dot(dZ2,A1.T)
dB2=1/mini_batch_size*np.Sum(dZ2,axis=1,keepdims=true)
dZ1=1/mini_batch_size*np.dot(W2.T,dZ2)*sigmoid_prime(Z1)
dW1=np.dot(dZ1,X.T)
dB1=1/mini_batch_size*np.dot(dZ1,axis=1,keepdims=true)

#update parameter
W2=W2-eta*dW2
W1=W1-eta*dW1
B1=B1-eta*dB1
B2=B2-eta*dB2
test_results=[(np.argmax(f(X,W1,W2,B1,B2)),y) for (x,y) is test_results]
num_correct=sum(int(x=y) for (x,y) in test_results)
print("Epoch {}:{}/{}". format(j,num_correct,n_test));
 return W1,B1,W2,B2
W1,B1,W2,B2=SGD(training_data,30,10,3,test_data)
